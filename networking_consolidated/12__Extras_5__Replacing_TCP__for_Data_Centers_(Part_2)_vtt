WEBVTT

00:00.230 --> 00:01.580
All right, section three.

00:01.850 --> 00:04.910
Everything about TCP is wrong.

00:05.940 --> 00:06.780
Not as that.

00:06.780 --> 00:07.020
Yeah.

00:07.020 --> 00:07.440
Of course.

00:07.440 --> 00:17.280
It's, uh, the language used in this paper is almost used in purpose to ruffle some feathers and ruffle

00:17.280 --> 00:18.780
some feathers are dead.

00:20.610 --> 00:22.230
I absolutely love it.

00:22.470 --> 00:23.280
Let's continue.

00:23.310 --> 00:28.860
This section discusses five key properties of TCP, which cover almost all of its designs.

00:30.110 --> 00:32.030
That's actually very interesting things.

00:32.180 --> 00:37.820
We can learn a lot about TCP from this, uh, this section really steam orientation.

00:38.150 --> 00:47.630
The idea of having concept of stream instead of messages, actual discrete start and end right here.

00:47.630 --> 00:48.320
Messages.

00:48.320 --> 00:53.210
There is no concept of messages or requests in TCP, right?

00:53.210 --> 00:57.470
You create this at the application layer.

00:57.470 --> 01:00.620
You are responsible to do that when you use TCP.

01:00.620 --> 01:06.080
And that's what Http does like Http has this header called Content-length.

01:06.080 --> 01:08.780
And that header has been abused to oblivion.

01:08.810 --> 01:10.670
Uh with Http smuggling attack.

01:10.670 --> 01:17.060
Most Http smuggling attack happens because of this stream orientation, right where we don't know where

01:17.060 --> 01:22.850
the message starts and where the message ends, and as a result, where the request starts and where

01:22.850 --> 01:23.600
the request ends.

01:23.600 --> 01:24.800
What makes it worse?

01:24.830 --> 01:27.110
Http has actually Http.

01:27.110 --> 01:33.800
The fluid design of Http has multiple ways to indicate an end right of a of a request.

01:33.800 --> 01:40.460
Like there is the content length and there is the what is it called the the transfer encoding I believe,

01:40.460 --> 01:44.540
which is like, hey, I don't know, I'm gonna abort to send unlimited stuff.

01:44.540 --> 01:52.040
So just, just, uh, be ready if I send like backslash n, backslash r, that's the end of my transmission

01:52.040 --> 01:52.940
I think twice.

01:52.940 --> 01:56.660
Slash and backslash, backslash backslash are that that basically.

01:56.660 --> 01:58.400
Hey that that ends my transmission.

01:58.400 --> 02:04.520
So just because we have multiple ways the problem is like what if you have content length and you have

02:04.520 --> 02:09.020
transmission encoding, the proxy will process it differently.

02:09.020 --> 02:13.580
And the back end let's say Node.js will trans will process it completely differently.

02:13.580 --> 02:21.500
And as a result, uh, hackers can smuggle, uh, sensitive requests in the second message that will

02:21.500 --> 02:29.090
be processed by that will be skipped completely by the proxy and will be processed by the application

02:29.090 --> 02:30.170
on the back end.

02:30.170 --> 02:36.500
This way, an attacker can call an admin API on the back end that has been actually blocked in the proxy.

02:36.500 --> 02:38.060
So that's what Http smuggling.

02:38.060 --> 02:43.220
And it's mostly because of the TCP streaming or orientation problem.

02:43.220 --> 02:43.760
Right?

02:44.030 --> 02:44.210
Right.

02:44.210 --> 02:46.010
They could have mentioned that but they didn't.

02:46.130 --> 02:54.830
That's like having clear definition of where the message starts and at the transport layer immediately

02:54.830 --> 02:55.850
solves this problem.

02:55.850 --> 02:58.700
We don't have a solution for this problem, unfortunately.

02:58.700 --> 03:02.420
That's why every two days you see uh, you see advisory.

03:02.420 --> 03:09.980
Oh, this magnet detector in Node.js, it's detected on, uh, in generic connection orientation.

03:10.760 --> 03:11.360
Correct.

03:11.450 --> 03:19.580
The idea of having TCP needs to have a connection because, well, I don't know why it needs to have

03:19.580 --> 03:20.120
a connection.

03:20.120 --> 03:21.140
Now after reading this.

03:21.140 --> 03:23.750
Like I am questioning everything to be honest.

03:23.750 --> 03:26.150
Like like like why why do you need a connection?

03:26.330 --> 03:26.810
Right.

03:26.840 --> 03:27.440
Yeah.

03:27.440 --> 03:31.580
It's like I have some state and you can store all the state in the connection.

03:31.580 --> 03:32.810
That's handy, right?

03:33.470 --> 03:41.600
You have port that comes to the port, you connect to a port and this way you can have the same host

03:41.600 --> 03:46.160
can have many applications and and the application is the connection level.

03:46.160 --> 03:52.280
You're going to see this the very similar thing right with the homa with the concept of RPC.

03:52.310 --> 03:53.150
But.

03:53.900 --> 03:55.280
Homer doesn't have connections.

03:55.280 --> 03:56.990
They removed all that together.

03:56.990 --> 03:59.690
You know, because we have connections in TCP.

03:59.690 --> 04:02.780
No, we need to store them and we need to store that state.

04:02.780 --> 04:07.910
And boy, if you have many connections, then you're going to need a lot of memory.

04:07.910 --> 04:10.190
There is a lot of management going on there.

04:10.790 --> 04:13.130
Bandwidth sharing, fair scheduling.

04:13.130 --> 04:18.080
So I didn't really, uh, know about this in TCP, to be honest.

04:18.080 --> 04:19.580
This is a new thing to me.

04:19.580 --> 04:22.520
Fair scheduling or fair queuing or whatever is called.

04:22.520 --> 04:25.730
I think TCP works at the segment level.

04:25.730 --> 04:32.780
So if you have a segment, if you have like ten connections coming, like all coming to your host,

04:32.780 --> 04:33.440
right?

04:34.580 --> 04:38.180
The segments will be processed in order in a fair manner like so.

04:38.180 --> 04:43.340
You have one segment, this segment, this segment, the segment, and it will just round robin through

04:43.340 --> 04:46.400
them one by one getting all these segments right.

04:46.400 --> 04:54.200
So if your segment happened to have one byte and the second segment is fully loaded with content, then

04:54.200 --> 04:55.550
you will be starved.

04:55.550 --> 04:59.090
Short messages will be starved in this example.

04:59.090 --> 04:59.660
Right.

04:59.660 --> 05:03.860
So short messages living in short segments will starve.

05:03.860 --> 05:05.390
That's how I understood it at least.

05:05.390 --> 05:05.570
Right?

05:05.570 --> 05:12.470
Because you'll have to wait because you're processing a larger messages segments while you have ten

05:12.470 --> 05:14.120
short segments, right.

05:14.120 --> 05:22.040
That needs to that can be processed quickly, but instead you decided to wait and, uh, serve larger

05:22.040 --> 05:22.790
segments, right?

05:22.790 --> 05:24.410
Because of just the order.

05:24.410 --> 05:25.010
It's just fair.

05:25.010 --> 05:25.370
Right?

05:25.370 --> 05:26.990
We'll we'll go through this in details.

05:26.990 --> 05:30.260
We'll talk about sender driven congestion control.

05:31.050 --> 05:32.310
We talked about this, right?

05:32.310 --> 05:37.350
The sender dictates the congestion and where we're going to send data and data.

05:37.470 --> 05:39.600
And data sense and sense and sensor up.

05:41.350 --> 05:41.890
I'm.

05:41.890 --> 05:43.420
I'm detecting congestion.

05:43.420 --> 05:46.180
My packets are not being acknowledged.

05:46.180 --> 05:49.030
My segments are not being acknowledged.

05:49.300 --> 05:51.280
Drop drop drop drop drop.

05:51.460 --> 05:51.730
Right.

05:51.730 --> 05:52.630
So the sender.

05:52.630 --> 05:58.120
That's effectively the bad thing about TCP in order packet delivery.

05:58.120 --> 06:00.340
So in order packet delivery.

06:00.580 --> 06:08.110
So the IP packets which carries the TCP segments which have the information about the sequence will

06:08.110 --> 06:10.930
have to be arrive in order.

06:10.930 --> 06:15.280
So even if your IP packets arrive out of order which will they will.

06:15.310 --> 06:15.730
Right.

06:15.730 --> 06:20.860
The end of the day, because it's the internet, I mean the data center, you can control that in a

06:20.860 --> 06:21.640
sense.

06:21.640 --> 06:23.740
Not not much in the internet.

06:23.740 --> 06:31.330
Then the application, the transport layer will start blocking says, oh, this is segment number three.

06:31.330 --> 06:32.410
Where is two and one.

06:32.410 --> 06:33.640
I'm going to wait for them.

06:33.640 --> 06:41.020
So the fact that you waited and you did not process segment three despite segment three being complete

06:41.290 --> 06:46.720
and a good message to be processed is a wasted latency, right?

06:46.720 --> 06:52.000
So the under an order packet delivery is kind of problematic.

06:52.000 --> 06:55.300
But we solve this problem.

06:55.300 --> 06:56.860
We know about this.

06:56.950 --> 07:03.400
We have this problem today with Http right a browser want to send ten requests right.

07:04.330 --> 07:08.830
How does it send ten requests to the same host in quick?

07:08.950 --> 07:12.910
We use UDP streams, which is the very similar concept.

07:12.910 --> 07:16.630
It's just UDP to avoid TCP head of line blocking.

07:16.930 --> 07:23.860
But in this case, yes, in this request they are they are completely independent streams.

07:23.860 --> 07:31.480
So the application when we arrive at the other end we're going to see oh this is, it's yeah we receive

07:31.480 --> 07:32.500
this segment.

07:32.500 --> 07:36.280
Segment number three arrived before segment number one.

07:36.280 --> 07:36.880
Sure.

07:36.880 --> 07:37.090
Yeah.

07:37.090 --> 07:42.040
They are out of order but they are completely its own stream.

07:42.040 --> 07:43.090
So I don't care.

07:43.090 --> 07:45.280
Take it and and start processing it.

07:45.280 --> 07:48.460
Do not wait for segment two and one to arrive.

07:48.460 --> 07:52.120
Or request 1 or 2 to arrive to process request number three.

07:52.120 --> 07:52.840
That's ridiculous.

07:52.840 --> 07:53.290
Right.

07:53.290 --> 07:58.690
So that's that's basically, uh, the idea of head of line blocking.

07:58.690 --> 08:01.990
Again, it still exists if you're using a TCP connection.

08:01.990 --> 08:08.590
That's why Http two, uh, still have the idea of head of line blocking at the TCP layer.

08:08.590 --> 08:11.020
So that's one limitation of TCP right there.

08:11.020 --> 08:11.380
Right.

08:12.040 --> 08:19.120
That's why quick solves that completely because quick has independent streams right.

08:20.590 --> 08:26.920
That's another reason why probably this paper never mentioned quick because same problem extremes.

08:26.920 --> 08:28.420
We don't care about streams.

08:28.420 --> 08:30.790
They don't want streams, they want messages.

08:31.000 --> 08:31.360
Right.

08:31.750 --> 08:34.660
So the idea of having stream, I wish that quick.

08:34.660 --> 08:40.420
They just thought of a concept to switch to messages and all of this will be gone.

08:40.420 --> 08:40.870
That's it.

08:40.870 --> 08:42.730
This this won't exist, right?

08:42.730 --> 08:46.360
If we just implemented in a quick.

08:47.790 --> 08:54.480
The idea of messages I don't think is going to be easy, but that that will solve the problem, right?

08:55.330 --> 08:56.710
Technically, because that's what they want.

08:56.710 --> 08:57.640
They want messages.

08:58.120 --> 09:03.610
But if you think about it like they also want other things, the congestion control we have congestion

09:03.610 --> 09:10.210
control and quick we have each stream is has its own congestion control limit.

09:10.330 --> 09:12.370
It's completely independent.

09:12.820 --> 09:13.120
Right.

09:13.330 --> 09:17.320
So but it's still limited by the sender.

09:17.320 --> 09:17.620
Right.

09:17.620 --> 09:23.410
So that's something they don't like I wish they really you know what they didn't mention anything about

09:23.410 --> 09:23.650
quick.

09:23.650 --> 09:24.730
And I'm mad.

09:24.760 --> 09:30.010
They really should talk about that because like why didn't you pick quick I know the answer.

09:30.010 --> 09:33.070
The answer is like it's stream, so it won't solve anything.

09:33.070 --> 09:36.190
Why not UDP just build on top of UDP?

09:36.190 --> 09:39.430
Probably they want to reinvent the wheel.

09:39.430 --> 09:43.270
They don't want to want that concept of ports which has it.

09:43.270 --> 09:44.110
UDP has it.

09:44.110 --> 09:45.880
They don't need this concept.

09:45.880 --> 09:51.520
Again I'm making a lot of things up implying and I'm not afraid of implying things because like hey,

09:51.520 --> 09:54.610
there's it's not written here and not nothing written here.

09:54.610 --> 09:55.840
And not in the other paper.

09:55.840 --> 09:58.510
So by the way, there is another paper right here.

09:58.570 --> 10:02.020
Uh, I'm going to share it with you, which is the actual home implementation.

10:02.020 --> 10:04.420
Back in 2018, I read that nothing.

10:04.420 --> 10:07.030
No mention of Quic, nothing.

10:07.700 --> 10:08.330
Let's read.

10:08.330 --> 10:09.020
Let's read.

10:09.230 --> 10:11.210
Stream orientation.

10:12.360 --> 10:14.790
The data model for TCP is stream of bytes.

10:14.820 --> 10:19.770
However, this is not the right model for most data center applications.

10:19.800 --> 10:26.460
Data center applications typically exchange discrete messages to implement remote procedure calls.

10:26.520 --> 10:27.120
Very critical.

10:27.120 --> 10:34.080
We talked about this right when you when you are in a data center or you have like a microservice talking

10:34.110 --> 10:38.850
to another Microsoft, it doesn't have to be Microsoft, just the normal data center thing, right?

10:38.850 --> 10:45.630
Whatever things they talk about these, you know, Kubernetes or whatever, you know, other, you know,

10:45.630 --> 10:49.830
host to host or whatever applications have in their data center.

10:49.830 --> 10:53.010
These communication happen as a request response.

10:53.010 --> 10:53.640
Give me a request.

10:53.640 --> 10:54.450
Give me a response.

10:55.750 --> 10:56.140
Yep.

10:57.560 --> 11:03.680
And the discreet message is the remote procedure call where, hey, I'm going to make a request.

11:03.680 --> 11:05.090
You give me a response.

11:05.360 --> 11:09.290
This means when an application reads from a stream.

11:10.060 --> 11:10.870
This is very important.

11:10.870 --> 11:11.980
That's why I highlighted it.

11:11.980 --> 11:16.060
There is no guarantee that it will receive a complete message.

11:17.650 --> 11:18.460
True.

11:18.460 --> 11:20.860
It's a stream you read.

11:20.860 --> 11:22.690
Whatever the Colonel will give you.

11:22.690 --> 11:23.440
Will give you.

11:23.770 --> 11:24.340
You don't know.

11:24.520 --> 11:28.330
That's why the application, the library, the Http library, for example.

11:28.330 --> 11:30.460
Node.js needs to continue reading.

11:30.460 --> 11:35.620
Reading until it's it's it gets a sense of what what is reading.

11:35.620 --> 11:37.480
I said, oh, it's a request.

11:37.480 --> 11:38.470
It's actually a request.

11:38.470 --> 11:42.460
So there is no guarantee you will receive a complete message or a complete request.

11:42.460 --> 11:43.810
Think of a message as a request here.

11:43.810 --> 11:44.230
Right.

11:44.830 --> 11:45.430
It could.

11:45.730 --> 11:50.980
It could receive less than a message, a full message or parts of several messages.

11:50.980 --> 11:51.340
Right?

11:51.340 --> 11:57.070
Because it might be the messages are so short you might receive, I don't know, three requests in a

11:57.070 --> 11:58.000
single read.

11:58.000 --> 12:02.380
Highly unlikely Http requests are so large, right?

12:03.060 --> 12:04.830
Large is like several bytes.

12:04.830 --> 12:06.180
It's going to be a lot of bytes.

12:06.180 --> 12:07.650
So I don't know, maybe.

12:07.650 --> 12:07.860
Yeah.

12:07.860 --> 12:15.060
If you make your request so short like get slash the minimum, no headers whatever the applicable headers

12:15.060 --> 12:15.630
you can do it.

12:15.630 --> 12:16.050
Yeah.

12:16.380 --> 12:18.870
Or use another protocol.

12:20.260 --> 12:27.220
The TCP based application must mark message boundaries when they serialize the messages.

12:27.220 --> 12:35.200
You have to encode your links somehow in the data so you're wasting precious data.

12:36.040 --> 12:44.170
From your side as an application to mark messages length, and you're responsible for managing the length

12:44.170 --> 12:45.460
and stuff like that.

12:45.790 --> 12:48.760
This is another important thing if multiple threads.

12:49.260 --> 12:56.220
Both read from a stream, it is possible that parts of a single message might be received by different

12:56.220 --> 12:56.700
thread.

12:56.730 --> 12:57.720
That's true, right?

12:57.720 --> 12:59.460
If the message is long.

12:59.490 --> 13:06.120
If a request is long and you have multiple threads reading from the same stream or socket or a connection,

13:06.120 --> 13:06.600
right?

13:06.630 --> 13:08.370
Think of a connection as a stream here.

13:08.370 --> 13:10.230
So not to be confused, right?

13:10.230 --> 13:15.000
Again, this overloaded of terms is is is really killing me.

13:15.000 --> 13:21.390
You know, I just I try to parse this paper, but you know, professors love to use abstractions as

13:21.390 --> 13:22.230
much as possible.

13:22.230 --> 13:24.900
So that's why I try to parse it.

13:24.900 --> 13:29.490
I try my best, I but a stream is a connection as far as I know here.

13:30.930 --> 13:31.890
A TCP connection.

13:32.100 --> 13:39.180
So if you're reading that stream of connection of data and multiple threads are reading it as one large

13:39.180 --> 13:43.710
request might be received from one thread and the other part will be received by the other.

13:43.710 --> 13:44.730
Yikes.

13:44.730 --> 13:48.300
That is the worst case scenario because like, oh hey, you got my request.

13:48.300 --> 13:50.520
Can you can you give me the request, please?

13:50.520 --> 13:52.830
So now coordination has to happen.

13:52.860 --> 13:53.790
It's so expensive.

13:53.790 --> 13:54.840
I have to agree with that.

13:54.840 --> 13:56.580
So yeah, this is the interesting thing.

13:56.580 --> 13:57.510
Load balancing.

13:57.510 --> 13:59.430
How do we actually solve this.

13:59.790 --> 14:08.340
The first approach used by memcache d is divide is to divide a collection of streams statically among

14:08.340 --> 14:13.470
the thread, where each thread handles all the requests arriving on its streams.

14:13.470 --> 14:16.320
So each each thread has a single stream.

14:16.320 --> 14:16.470
Why?

14:16.770 --> 14:18.030
Why can't we just say this?

14:18.210 --> 14:20.430
Each thread gets a stream basically right?

14:20.430 --> 14:22.980
So one thread, one stream, one thread, one stream.

14:22.980 --> 14:23.610
The.

14:23.610 --> 14:29.400
This approach is prone to because this way you don't you want you know you're not going to get the like

14:29.400 --> 14:34.560
the two threads dealing with multiple you know same requests right.

14:34.560 --> 14:36.480
All the requests will be handled by a thread.

14:36.480 --> 14:38.580
But now this is a problem with the hotspot.

14:38.580 --> 14:43.470
You're going to get a hotspot problem where one connection will be so busy and the other connection

14:43.470 --> 14:48.900
is so light, so one thread will be overloaded and the other thread won't be overloaded.

14:49.440 --> 14:51.840
And that's a problem in, I guess, in memcached.

14:51.870 --> 14:58.260
But then the second approach used by Ram cloud dedicates one thread to read all incoming messages from

14:58.260 --> 14:59.670
all connections.

14:59.670 --> 15:01.830
So all connections one thread.

15:02.560 --> 15:03.040
It's up to you.

15:03.040 --> 15:04.870
You can design it any, any way you want.

15:04.900 --> 15:05.950
What's the problem with this?

15:05.950 --> 15:14.050
So this is so this thread reads all the messages, all the stream data, which is a bunch of segments,

15:14.050 --> 15:21.130
which now becomes a stream of data and now dispatches the dispatch messages to the thread.

15:21.130 --> 15:27.580
So that thread is responsible to breaking down the boundaries of the message.

15:27.640 --> 15:29.410
It's like, oh, you are a Http request.

15:29.410 --> 15:30.880
Wait, where do you start?

15:30.880 --> 15:31.930
You start here.

15:31.930 --> 15:35.140
Oh, this is where you end because your content length is so it needs to pass.

15:35.140 --> 15:38.200
This all takes CPU processing power right?

15:38.440 --> 15:43.330
And then so imagine if this we can be offloaded to somewhere else.

15:43.360 --> 15:50.290
That'll be really interesting I just I love absolutely love that part where the message boundary is

15:50.290 --> 15:53.230
handled at the transport layer.

15:54.450 --> 15:58.080
I loved this, I loved this, in this design, we.

15:58.080 --> 16:00.660
It's a novel idea that I never.

16:00.780 --> 16:01.230
Yeah.

16:01.230 --> 16:05.220
Because to me, I always think of messages or requests being processed.

16:05.220 --> 16:06.150
Application layer.

16:06.150 --> 16:07.050
But why?

16:07.050 --> 16:11.340
Why do we have to why why not push this down at the layer four.

16:11.340 --> 16:15.300
Let layer four does it this stuff an even better.

16:15.480 --> 16:19.620
Offload this to the Nic, although I don't know if it's a good idea, I think it's going to bite us

16:19.620 --> 16:24.750
in the butt in the future if we float everything to the neck, right?

16:24.750 --> 16:27.540
I don't know, I don't know anything, you guys.

16:29.000 --> 16:34.340
Dedicates one thread to read all the incoming messages from all streams, and then dispatch messages

16:34.340 --> 16:35.300
to the thread of the server.

16:35.300 --> 16:37.880
So the thread is doing a lot of work here.

16:38.660 --> 16:44.960
This is also much better load balancing work because now the thread knows which thread is which, which

16:44.960 --> 16:46.430
thread each thread is doing right.

16:46.430 --> 16:47.960
That's actually very interesting.

16:48.200 --> 16:50.510
So you can do a better load balancing.

16:50.510 --> 16:51.950
There is no hotspotting.

16:53.110 --> 16:55.750
Man, this is a completely different world.

16:55.750 --> 17:03.220
You know, I absolutely love this, but the dispatcher thread becomes a throughput bottleneck.

17:03.220 --> 17:04.390
It makes sense, right?

17:04.930 --> 17:06.190
It becomes a bottleneck.

17:06.220 --> 17:12.460
The fundamental problem with streaming is that units of way in which data is received, ranges of by

17:12.490 --> 17:15.190
do not correspond to dispatchable units.

17:15.670 --> 17:17.050
Work of messages.

17:17.050 --> 17:18.010
Why not?

17:18.530 --> 17:19.160
Why not?

17:19.190 --> 17:20.930
Why not let me let me challenge that.

17:20.930 --> 17:22.160
Let me challenge that.

17:22.280 --> 17:24.830
Can we fix that with DCP?

17:25.280 --> 17:26.480
Can we fix that.

17:27.350 --> 17:28.670
Can I?

17:30.700 --> 17:34.660
Assuming we don't have a limit in my M2, right?

17:36.400 --> 17:38.560
Assume I don't have a limited time to you.

17:39.780 --> 17:40.230
Right?

17:40.230 --> 17:43.830
Because I'm in the data center I'm going to make, I don't know, one gig, my M2.

17:43.830 --> 17:45.150
I don't know if that's even possible.

17:45.150 --> 17:47.340
Let's say it is right.

17:47.790 --> 17:50.910
That means my IP package is so large, right?

17:51.270 --> 17:55.890
Can we even have a gig IP packet two to power what 16 bit.

17:55.890 --> 18:00.600
So that gives us 65 K.

18:01.440 --> 18:02.700
That is tiny dude.

18:02.700 --> 18:07.380
So the largest MTU we can get is 65 K in IPv4 right.

18:07.950 --> 18:11.250
That is tiny dude 65 K.

18:11.250 --> 18:13.680
So that's the largest MTU we can get.

18:13.680 --> 18:15.420
All right okay.

18:15.420 --> 18:17.550
That is tiny I have to agree with you.

18:17.550 --> 18:17.760
All right.

18:17.760 --> 18:20.100
But I'm still going to continue my theory here.

18:20.490 --> 18:20.760
Right?

18:20.760 --> 18:22.110
IPv6.

18:22.110 --> 18:23.910
Uh let's see IPv6.

18:23.910 --> 18:26.010
Yeah it sounds like a 60 4k.

18:26.010 --> 18:26.550
All right.

18:26.760 --> 18:28.140
Uh, regardless let's go back.

18:28.140 --> 18:28.620
All right.

18:28.620 --> 18:30.870
Let's let's let's stick with this.

18:31.960 --> 18:32.320
All right.

18:32.320 --> 18:38.410
So let's say the MTU is 65 K because apparently anything larger than that doesn't make sense because

18:38.410 --> 18:40.630
it can't fit the IP header.

18:40.630 --> 18:45.130
And where did I hear that that sometimes the payload is zero.

18:45.130 --> 18:50.020
So you put the payload length as zero and you can put whatever you want there.

18:50.020 --> 18:52.180
I'm pretty sure there was I read something like that.

18:52.180 --> 18:54.760
I might be wrong, but yeah let's assume 65 K.

18:54.760 --> 18:57.700
Like don't send any message larger than 65 K.

18:57.700 --> 18:57.910
All right.

18:57.910 --> 19:00.490
Let's let's let's let's put some restriction here.

19:00.490 --> 19:06.790
So now the MTU that large then you have the frame is 65 K obviously.

19:06.790 --> 19:09.070
And then you have the IP packet is the 65 K.

19:09.070 --> 19:15.700
And then as a result the MSS will be 65 K minus whatever 40 bytes for the headers.

19:16.480 --> 19:17.560
That's beautiful.

19:17.560 --> 19:19.360
Right this way.

19:19.360 --> 19:22.180
Now you can control each message you send.

19:22.180 --> 19:24.250
Actually send it in a segment.

19:24.250 --> 19:32.290
So now if your message is a thousand bytes have a low level API which you I believe you can flush the

19:32.290 --> 19:34.330
segment one segment.

19:34.330 --> 19:41.530
It doesn't have to be full and have your application treat the segment as a message.

19:41.980 --> 19:43.540
Can we do this?

19:43.540 --> 19:44.770
Can we do this?

19:44.800 --> 19:45.640
Is this even possible?

19:45.640 --> 19:46.930
I'm just challenging this.

19:46.930 --> 19:48.820
I don't know if it's possible or not.

19:49.330 --> 19:57.730
If you can Ncbi treat the segment as a unit of work, then for free we got the length you guys.

19:57.730 --> 19:59.320
That's the message length.

19:59.870 --> 20:01.310
Can we do this?

20:01.910 --> 20:04.340
Can we do this, you guys?

20:05.040 --> 20:06.090
Maybe not.

20:06.660 --> 20:07.170
Maybe.

20:07.170 --> 20:07.800
Yes.

20:07.830 --> 20:08.310
Right.

20:08.400 --> 20:15.870
Unless if this is like if this is if middle middle router tried to play with the segments and retransmit

20:15.870 --> 20:17.580
it, I cannot guarantee that.

20:17.580 --> 20:19.740
I don't think we can guarantee the segment size.

20:19.740 --> 20:20.100
Right.

20:20.100 --> 20:22.200
If you have proxies, forget about it.

20:22.200 --> 20:22.500
Right.

20:22.500 --> 20:26.520
If you have like end to end, the host is behind a proxy.

20:26.520 --> 20:26.850
Right.

20:26.850 --> 20:30.750
And then the proxy is like you're establishing a connection between you and the proxy.

20:30.750 --> 20:35.010
And the proxy establish connection with the back end, uh, actual back end.

20:35.010 --> 20:39.600
Then you, the proxy have to rewrite these segments to the to the back end.

20:39.600 --> 20:39.870
Right.

20:39.870 --> 20:47.100
So you have to make sure the proxy is actually rewriting the same segment sizes, which you cannot guarantee

20:47.100 --> 20:51.960
because there is no these these are not written in stone as far as I know.

20:51.960 --> 20:52.200
Right.

20:52.200 --> 20:58.950
These segment sizes like whatever you receive doesn't won't necessarily go into that I think.

20:58.950 --> 21:00.330
So it might work.

21:00.330 --> 21:00.840
It might not.

21:00.840 --> 21:04.110
But I guess it's safer to create a new protocol.

21:04.380 --> 21:07.920
But I know I would like to give it a try first.

21:07.920 --> 21:14.460
It would be better for each message to be dispatched to a different thread, so messages can be processed

21:14.460 --> 21:15.570
concurrently.

21:15.570 --> 21:21.390
So that's another advantage now that if the thread knows where the message starts, where the message

21:21.390 --> 21:26.100
ends, then it can be, oh, this is one message he thread ticket emitted.

21:26.100 --> 21:26.850
One ticket.

21:26.850 --> 21:27.330
Right?

21:27.330 --> 21:28.110
That's the same thing.

21:28.110 --> 21:31.980
If you if we somehow can guarantee that's what I'm saying, right.

21:31.980 --> 21:39.690
If you can somehow guarantee a message fitting in a single segment, then we can solve this, right?

21:40.290 --> 21:41.490
Can we guarantee that?

21:41.490 --> 21:42.720
I don't have an answer to that.

21:42.720 --> 21:43.500
Let's read this.

21:43.500 --> 21:50.100
Highlighted that I highlighted the red for some reason in this word, the nick should perform load balancing,

21:50.100 --> 21:56.670
dispatching incoming requests across a collection of application threads via kernel bypass.

21:56.670 --> 22:03.750
However, this will not be possible since information about message boundaries is application specific

22:03.750 --> 22:05.820
and unknown to transport layer.

22:05.820 --> 22:09.930
I think I mentioned that, but I highlighted it here again because it's so important.

22:09.930 --> 22:16.980
The fact that the information, the metadata about the message is available at the transport layer is

22:16.980 --> 22:21.150
so powerful, which you think about it, the segment does have a size, right?

22:21.150 --> 22:25.380
The the the length of the actual content of the segment.

22:25.380 --> 22:27.810
This is how that's the length of the segment.

22:27.810 --> 22:29.520
It does have that right.

22:29.520 --> 22:30.540
The data length.

22:30.870 --> 22:31.380
Right.

22:31.380 --> 22:34.980
But maybe it's not guaranteed.

22:35.590 --> 22:36.550
Right.

22:36.730 --> 22:38.830
That's why we cannot use it.

22:39.590 --> 22:47.030
Okay, but what they are inventing effectively is inventing the same concept of a segment, but as a

22:47.090 --> 22:49.340
as a decree, a discreet message here.

22:50.030 --> 22:56.510
Obviously it's more complicated than I'm mentioning, but but yeah, if the if the Nick for example,

22:56.510 --> 23:00.830
knows about the length, it can, it can do the work and then immediately dispatch the message to the

23:00.830 --> 23:01.160
thread.
